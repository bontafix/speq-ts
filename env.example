# ==============================================================================
# БАЗА ДАННЫХ (PostgreSQL)
# ==============================================================================

PGHOST=localhost
PGPORT=5432
PGUSER=postgres
PGPASSWORD=your_password
PGDATABASE=equipment_catalog

# ==============================================================================
# TELEGRAM BOT
# ==============================================================================

# Токен Telegram-бота от @BotFather
TELEGRAM_BOT_TOKEN=

# Необязательно: переопределить API root (если используете прокси/локальный Bot API).
# По умолчанию Telegraf ходит в https://api.telegram.org
# TELEGRAM_API_ROOT=https://api.telegram.org

# ==============================================================================
# LLM ПРОВАЙДЕРЫ
# ==============================================================================

# Выбор провайдера для chat completion (парсинг запросов, генерация ответов)
# ВАЖНО: в этом проекте для чата используется ТОЛЬКО Groq API.
LLM_CHAT_PROVIDER=groq

# Выбор провайдера для embeddings (векторный поиск)
# Варианты: ollama | openai
# Примечание: Groq пока не поддерживает embeddings
LLM_EMBEDDINGS_PROVIDER=ollama

# Fallback провайдеры (через запятую, в порядке приоритета)
# Примечание: fallback применяется для embeddings/векторного поиска.
# Для chat fallback отключён — чат всегда идёт только через Groq.
LLM_FALLBACK_PROVIDERS=ollama,openai

# Тихий режим fallback (не логировать переключение провайдеров)
LLM_FALLBACK_SILENT=false

# ==============================================================================
# OLLAMA (локальный сервер)
# ==============================================================================

OLLAMA_BASE_URL=http://127.0.0.1:11434

# Модель для chat completion (парсинг запросов)
# ВАЖНО: чат в этом проекте идёт через Groq, поэтому LLM_MODEL должен быть Groq-моделью.
# Рекомендуемая дефолтная модель:
LLM_MODEL=llama-3.3-70b-versatile

# Модель для embeddings (векторный поиск)
# Рекомендуемые модели:
# - nomic-embed-text (384 или 768 измерений, хорошее качество)
# - all-minilm (быстрая, компактная)
EMBED_MODEL=nomic-embed-text

# Размер батча для worker эмбеддингов
EMBED_BATCH_SIZE=32

# ==============================================================================
# GROQ (облачный API)
# ==============================================================================

# API ключ Groq (получить на https://console.groq.com)
# Оставьте пустым, если не используете Groq
GROQ_API_KEY=

# Base URL для Groq API (обычно не нужно менять)
# Важно: для groq-sdk base URL должен быть БЕЗ суффикса "/openai/v1"
# (SDK сам добавляет этот префикс).
GROQ_BASE_URL=https://api.groq.com

# Рекомендуемые модели Groq:
# При использовании Groq:
# LLM_CHAT_PROVIDER=groq
# LLM_MODEL=llama-3.3-70b-versatile  (очень быстрая и качественная, рекомендуется)
# или
# LLM_MODEL=llama-3.1-70b-versatile  (альтернатива)
# или
# LLM_MODEL=llama-3.1-8b-instant  (быстрая, компактная)
# или
# LLM_MODEL=mixtral-8x22b-instruct  (Mixtral MoE, большой контекст)
# или
# LLM_MODEL=gemma2-9b-it  (компактная модель Google)
#
# Получить список всех доступных моделей можно через API:
# GET https://api.groq.com/openai/v1/models (требует API ключ)

# ==============================================================================
# OPENAI (облачный API)
# ==============================================================================

# API ключ OpenAI (получить на https://platform.openai.com/api-keys)
# Оставьте пустым, если не используете OpenAI
OPENAI_API_KEY=

# Base URL для OpenAI API (обычно не нужно менять)
OPENAI_BASE_URL=https://api.openai.com/v1

# Рекомендуемые модели OpenAI:
# ВАЖНО: чат через OpenAI в этом проекте отключён.
# OpenAI имеет смысл использовать только для embeddings, если нужно.

# Для embeddings:
# LLM_EMBEDDINGS_PROVIDER=openai
# EMBED_MODEL=text-embedding-3-small  (дешевая)
# или
# EMBED_MODEL=text-embedding-3-large  (высокое качество)

# ==============================================================================
# ПОИСК
# ==============================================================================

# Включить векторный поиск (pgvector)
# Требует наличия функции equipment_vector_search в БД
ENABLE_VECTOR_SEARCH=false

# ==============================================================================
# HTTP API
# ==============================================================================

# Порт для HTTP сервера
# Для webhook режима рекомендуется использовать порт 7504
# (если на сервере несколько ботов на разных портах)
HTTP_PORT=3000
# HTTP_PORT=7504  # Для webhook режима с nginx на маршруте /speq-bot

# ==============================================================================
# ИЗОБРАЖЕНИЯ
# ==============================================================================

# Базовый URL для изображений оборудования
# Формат: https://domain.com (без завершающего слеша)
# Изображения будут доступны по адресу: {IMAGE_BASE_URL}/speq-images/{equipment_id}
# Пример: https://example.com/speq-images/1455
# Если не задан, изображения не будут отправляться в Telegram
IMAGE_BASE_URL=

# ==============================================================================
# ПРИМЕРЫ КОНФИГУРАЦИЙ
# ==============================================================================

# 1. Полностью локальная разработка (бесплатно, без интернета):
#    LLM_CHAT_PROVIDER=ollama
#    LLM_EMBEDDINGS_PROVIDER=ollama
#    LLM_MODEL=qwen2.5:7b-instruct-q4_K_M
#    EMBED_MODEL=nomic-embed-text

# 2. Быстрый парсинг через Groq + локальные embeddings (почти бесплатно):
#    LLM_CHAT_PROVIDER=groq
#    LLM_EMBEDDINGS_PROVIDER=ollama
#    LLM_MODEL=llama-3.3-70b-versatile
#    EMBED_MODEL=nomic-embed-text
#    GROQ_API_KEY=your_groq_key

# 3. Максимальное качество через OpenAI (платно):
#    LLM_CHAT_PROVIDER=openai
#    LLM_EMBEDDINGS_PROVIDER=openai
#    LLM_MODEL=gpt-4o
#    EMBED_MODEL=text-embedding-3-large
#    OPENAI_API_KEY=your_openai_key

# 4. Groq с fallback на Ollama (надежность):
#    LLM_CHAT_PROVIDER=groq
#    LLM_FALLBACK_PROVIDERS=ollama
#    GROQ_API_KEY=your_groq_key

